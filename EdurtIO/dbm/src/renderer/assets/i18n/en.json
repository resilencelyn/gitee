{
  "common": {
    "management": "Management",
    "datasource": "DataSource",
    "add": "Add",
    "refresh": "Refresh",
    "close": "Close",
    "alias": "Alias",
    "protocol": "Protocol",
    "host": "Host",
    "port": "Port",
    "username": "User Name",
    "password": "Password",
    "ok": "OK",
    "test": "Test",
    "action": "Action",
    "delete": "Delete",
    "edit": "Edit",
    "name": "Name",
    "query": "Query",
    "execute": "Execute",
    "history": "History",
    "format": "Format",
    "cancel": "Cancel",
    "select": "Select",
    "quick": "Quick",
    "result": "Result",
    "editor": "Editor",
    "id": "ID",
    "server": "Server",
    "state": "State",
    "time": "Time",
    "start": "Start",
    "end": "End",
    "elapsed": "Elapsed",
    "ddl": "DDL",
    "error": "Error",
    "database": "Database",
    "table": "Table",
    "tools": "Tools",
    "system": "System",
    "monitor": "Monitor",
    "language": "Language",
    "track": "Track",
    "exception": "Exception",
    "stack": "Stack",
    "copy": "Copy",
    "basic": "Basic",
    "network": "Network",
    "timeout": "Timeout",
    "setting": "Setting",
    "clear": "Clear",
    "processor": "Processor",
    "open": "Open",
    "detail": "Detail",
    "active": "Active",
    "line": "Line",
    "theme": "Theme",
    "preview": "Preview",
    "number": "Number",
    "connection": "Connection",
    "metadata": "Metadata",
    "disk": "Disk",
    "info": "Information",
    "create": "Create",
    "engine": "Engine",
    "configuration": "Configuration",
    "previous": "Previous",
    "next": "Next",
    "experimental": "Experimental",
    "default": "Default",
    "save": "Save",
    "property": "Property",
    "atomic": "Atomic",
    "expiration": "Expiration",
    "lazy": "Lazy",
    "mysql": "MySQL",
    "materialized_mysql": "MaterializeMySQL",
    "github": "GitHub",
    "drop": "Drop",
    "structure": "Structure",
    "log": "Log",
    "column": "Column",
    "tinylog": "TinyLog",
    "stripelog": "StripeLog",
    "integration": "Integration",
    "broker": "Broker",
    "topic": "Topic",
    "group": "Group",
    "uri": "URI",
    "jdbc": "JDBC",
    "sqlite": "SQLite",
    "path": "Path",
    "odbc": "ODBC",
    "rename": "Rename",
    "truncate": "Truncate",
    "rollback": "Rollback",
    "no_rollback": "No Rollback",
    "clean": "Clean",
    "partition": "Partition",
    "optimize": "Optimize",
    "final": "Final",
    "mutations": "Mutations",
    "migrte": "Migrate",
    "target": "Target",
    "source": "Source",
    "nullable": "Nullable",
    "current": "Current",
    "version": "Version",
    "latest": "Latest",
    "download": "Download",
    "update": "Update",
    "new": "New",
    "percentage": "Percentage",
    "release": "Release",
    "note": "Note",
    "type": "Type",
    "rowDelimiter": "Row Delimiter",
    "optional": "Optional",
    "schema": "Schema",
    "numOfConsumer": "Number Of Consumer",
    "maxBlockSize": "Max Block Size",
    "skipBrokenMessages": "Skip Broken Messages",
    "commitEveryBatch": "Commit Every Batch",
    "threadPerConsumer": "Thread Per Consumer",
    "clickhouse": "ClickHouse",
    "advanced": "Advanced",
    "maxTotal": "MaxTotal",
    "quicklyEnter": "Quickly enter",
    "export": "Export",
    "csv": "CSV",
    "result": "Result",
    "collection": "Collection",
    "options": "Options",
    "ttl": "TTL",
    "custom": "Custom",
    "simple": "Simple",
    "modify": "Modify",
    "remove": "Remove",
    "status": "Status",
    "success": "Success",
    "description": "Description",
    "comment": "Comment",
    "snippet": "Snippet",
    "id": "ID",
    "name": "Name",
    "description": "Description",
    "code": "Code",
    "created": "Created",
    "updated": "Updated",
    "quote": "Quote",
    "sshHost": "SSH Host",
    "sshPort": "SSH Port",
    "sshUsername": "SSH User",
    "sshPassword": "SSH Password",
    "more": "More",
    "matchBrackets": "Match Brackets",
    "filter": "Filter",
    "precise": "Precise"
  },
  "language": {
    "english": "English",
    "chinese": "Chinese"
  },
  "placeholder": {
    "alias": "Please input alias name!",
    "protocol": "Please select protocol type!",
    "host": "Please input host!",
    "port": "Please input port!",
    "username": "Please input username!",
    "password": "Please input password!",
    "database": "Please input database [Optional]",
    "broker": "Please input kafka broker list",
    "topic": "Please enter Kafka consumption topic for consumption",
    "group": "Please enter the consuming Kafka message topic owning group",
    "format": "Please enter the data parsing format",
    "uri": "Please enter the remote server address",
    "table": "Please input table name",
    "path": "Please input file path",
    "setting": "Please input setting file path",
    "name": "Please input name",
    "rowDelimiter": "delimiter symbol",
    "schema": "Schema",
    "numOfConsumer": "Number Of Consumer",
    "maxBlockSize": "Max Block Size",
    "skipBrokenMessages": "Skip Broken Messages",
    "commitEveryBatch": "Commit Every Batch",
    "threadPerConsumer": "Thread Per Consumer",
    "maxTotal": "The maximum number of rows is displayed. If you manually enter limit, the configuration is overwritten. If 0 is set, the configuration does not take effect",
    "collection": "Please input collection",
    "required": "This value cannot be empty, please enter"
  },
  "tooltip": {
    "network": "Duration of accessing the remote server (in seconds)",
    "format": "The underlying data supports formatting types, JSON by default",
    "language": "The language used by the software is English by default",
    "experimental": "This is an experimental feature that should not be used in production.",
    "elapsed": "Total Time (sec)",
    "rowsRead": "The total number of rows of data read",
    "bytesRead": "The total number of bytes of data read",
    "execute": "Press Ctrl+Enter to execute the command",
    "rows": "Return total number of rows of data",
    "editor": {
      "preview": "Real-time feedback on editor modification status",
      "activeLine": "Highlight the current selection row shown with the mouse",
      "theme": "Global editor theme",
      "lineNumber": "Shows the number of lines of code",
      "language": "Type of editor formatting"
    },
    "database": {
      "default": "Default Database Engine",
      "atomic": "It supports non-blocking DROP TABLE and RENAME TABLE queries and atomic EXCHANGE TABLES queries. Atomic database engine is used by default.",
      "lazy": "Keeps tables in RAM only expiration_time_in_seconds seconds after last access. Can be used only with *Log tables.",
      "mysql": "Allows to connect to databases on a remote MySQL server and perform INSERT and SELECT queries to exchange data between ClickHouse and MySQL.",
      "materialized_mysql": "Creates ClickHouse database with all the tables existing in MySQL, and all the data in those tables. ClickHouse server works as MySQL replica. It reads binlog and performs DDL and DML queries."
    },
    "table": {
      "log": "Lightweight engines with minimum functionality. They’re the most effective when you need to quickly write many small tables (up to approximately 1 million rows) and read them later as a whole.",
      "integration": "It is mainly used to import external data into ClickHouse, or to manipulate external data sources directly in ClickHouse.",
      "kafka": "Import data from Kafka Topic directly into ClickHouse",
      "hdfs": "Import data from HDFS directly into ClickHouse",
      "jdbc": "Allows ClickHouse to connect to external databases via JDBC",
      "sqlite": "The engine allows to import and export data to SQLite and supports queries to SQLite tables directly from ClickHouse.",
      "odbc": "Allows ClickHouse to connect to external databases via ODBC",
      "mongodb": "MongoDB engine is read-only table engine which allows to read data (SELECT queries) from remote MongoDB collection. Engine supports only non-nested data types. INSERT queries are not supported."
    },
    "property": {
      "timeSeconds": "Retention time in RAM (unit per second)",
      "host": "IP address or host name of the remote server",
      "port": "Port that the remote server is bound to",
      "database": "Database in an external DBMS",
      "username": "User name that authorizes access",
      "password": "The password of the authorized user",
      "broker": "List of Kafka Broker services, typically IP:9092",
      "topic": "Consuming kafka message topic",
      "group": "The consuming Kafka message topic belongs to a group, anonymous by default",
      "format": "The data format type varies from engine to engine",
      "uri": "URI or name of an external DBMS.\nURI Format: jdbc:<driver_name>://<host_name>:<port>/?user=<username>&password=<password>",
      "table": "Name of the table in database",
      "path": "Path to file with a database",
      "final": "When FINAL is specified, ClickHouse fully merges the data before returning the result and thus performs all data transformations that happen during merges for the given table engine",
      "rowDelimiter": "Delimiter character, which ends the message.",
      "schema": "Parameter that must be used if the format requires a schema definition. For example, Cap’n Proto requires the path to the schema file and the name of the root schema.capnp:Message object.",
      "numOfConsumer": "The number of consumers per table. Default: 1. Specify more consumers if the throughput of one consumer is insufficient. The total number of consumers should not exceed the number of partitions in the topic, since only one consumer can be assigned per partition.",
      "maxBlockSize": "The maximum batch size (in messages) for poll (default: max_block_size).",
      "skipBrokenMessages": "Kafka message parser tolerance to schema-incompatible messages per block. Default: 0. If kafka_skip_broken_messages = N then the engine skips N Kafka messages that cannot be parsed (a message equals a row of data).",
      "commitEveryBatch": "Commit every consumed and handled batch instead of a single commit after writing a whole block (default: 0).",
      "threadPerConsumer": "Provide independent thread for each consumer (default: 0). When enabled, every consumer flush the data independently, in parallel (otherwise — rows from several consumers squashed to form one block).",
      "setting": {
        "odbc": "Name of the section with connection settings in the odbc.ini file"
      },
      "mongodb": {
        "uri": "MongoDB server address",
        "collection": "Remote collection name",
        "database": "Remote database name",
        "username": "MongoDB user",
        "password": "User password",
        "options": "MongoDB connection string options (optional parameter)"
      }
    },
    "source": {
      "basic": "Basic DataSource Type",
      "clickhouse": "Integrate ClickHouse data sources"
    }
  },
  "alert": {
    "rename": "The RENAME query is supported by the Atomic database engine only",
    "truncate": "This operation deletes all data, but does not delete the table",
    "noversion": "This is the latest version!",
    "not_support_online": "Currently, online updates are not supported",
    "table_grate_50": "Data tables larger than 50GB cannot be migrated",
    "table_delete_grate_50": "Data tables larger than 50GB cannot be deleted",
    "ttl": "When the time reaches, the system deletes data in the entire table based on the configured TTL",
    "ttl_remove": "After the TTL configuration is removed, the system will not delete data",
    "only_one_column": "You cannot delete all columns in a data table, the table must contain at least one column",
    "delete_it": "We don't recommend that you delete it? This operation produces the following?",
    "migrate_datasource": "The storage method of the data source has been modified. Please continue to use the original storage content after migrating the data.",
    "migrate_data_success": "After the migration is successful, the source data will be cleaned up!"
  },
  "formatter": {
    "migrate_data": "Need to migrate {0} data, please confirm whether to migrate?"
  }
}
